{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, chi2\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "grandparent_dir = os.path.abspath(os.path.join(parent_dir, os.pardir))\n",
    "sys.path.insert(0, parent_dir)\n",
    "sys.path.insert(0, grandparent_dir)\n",
    "import cmds.portfolio_management_helper as pmh\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "PLOT_WIDTH, PLOT_HEIGHT = 8, 5\n",
    "COLORS = [\"blue\", \"red\", \"orange\"]\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "p = plt.rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = parent_dir + '/data/'\n",
    "ff_file_name = data_path + 'momentum_data.xlsx'\n",
    "excess_ff_factors = pmh.read_excel_default(ff_file_name, \n",
    "                                 sheet_name='factors (excess returns)',\n",
    "                                 index_col='Date', parse_dates=True)\n",
    "excess_momentum = pmh.read_excel_default(ff_file_name, \n",
    "                                 sheet_name='momentum (excess returns)',\n",
    "                                 index_col='Date', parse_dates=True)\n",
    "total_deciles = pmh.read_excel_default(ff_file_name, \n",
    "                                 sheet_name='deciles (total returns)',\n",
    "                                 index_col='Date', parse_dates=True)\n",
    "total_size_sorts = pmh.read_excel_default(ff_file_name, \n",
    "                                 sheet_name='size_sorts (total returns)',\n",
    "                                 index_col='Date', parse_dates=True)\n",
    "rf_rate = pmh.read_excel_default(ff_file_name, \n",
    "                                 sheet_name='risk-free rate',\n",
    "                                 index_col='Date', parse_dates=True)\n",
    "\n",
    "barn_file_name = data_path + 'barnstable_analysis_data.xlsx'\n",
    "barn_rets = pmh.read_excel_default(barn_file_name, \n",
    "                                 sheet_name='data',\n",
    "                                 index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmh.calc_summary_statistics(factors, annual_factor=12, correlations=False, provided_excess_returns=True,\n",
    "                            keep_columns=['Annualized Mean',\n",
    "                                            'Annualized Vol',\n",
    "                                            'Annualized Sharpe',\n",
    "                                            'Annualized Historical VaR',\n",
    "                                            'Annualized Historical CVaR']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Timeframes (with Correlations!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pmh.calc_summary_statistics(ff_factors, annual_factor=12, provided_excess_returns=True, \n",
    "                            timeframes={'1927-2024':['1927', '2024'],\n",
    "                                        '1927-1993':['1927', '1993'],\n",
    "                                        '1994-2008':['1994', '2008'],\n",
    "                                        '2009-2024':['2009', '2024']},\n",
    "                            correlations=['MKT', 'HML'],\n",
    "                            keep_columns=['Annualized Mean', 'Annualized Vol', 'Annualized Sharpe', 'Skewness', 'Correlation'])\n",
    "summary_table.loc[summary_table.index.str.contains('UMD')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Re-Formatting :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barn_rets['SPX-XS'] = barn_rets['SPX'] - barn_rets['TB1M']\n",
    "barn_rets['LOG_SPX'] = np.log(1 + barn_rets['SPX'])\n",
    "barn_rets['LOG_TB1M'] = np.log(1 + barn_rets['TB1M'])\n",
    "barn_rets['LOG_SPX-XS'] = np.log(1 + barn_rets['SPX-XS'])\n",
    "\n",
    "# Initial Summary Table\n",
    "barn_summary_table = pmh.calc_summary_statistics(barn_rets, annual_factor=12, provided_excess_returns=True,\n",
    "                            timeframes={'1965-1999': ['1965', '1999'],\n",
    "                                        '2000-2024':['2000', '2024'],\n",
    "                                        '1926-2024':['1926', '2024']}, correlations=False,\n",
    "                            keep_columns=['Annualized Mean', 'Annualized Vol'])\n",
    "\n",
    "# Stripping out Quadrants\n",
    "logs_1965 = barn_summary_table.loc[barn_summary_table.index.str.contains('LOG') & barn_summary_table.index.str.contains('1965')]\n",
    "logs_2000 = barn_summary_table.loc[barn_summary_table.index.str.contains('LOG') & barn_summary_table.index.str.contains('2000')]\n",
    "logs_1926 = barn_summary_table.loc[barn_summary_table.index.str.contains('LOG') & barn_summary_table.index.str.contains('1926')]\n",
    "\n",
    "levels_1965 = barn_summary_table.loc[~barn_summary_table.index.str.contains('LOG') & barn_summary_table.index.str.contains('1965')]\n",
    "levels_2000 = barn_summary_table.loc[~barn_summary_table.index.str.contains('LOG') & barn_summary_table.index.str.contains('2000')]\n",
    "levels_1926 = barn_summary_table.loc[~barn_summary_table.index.str.contains('LOG') & barn_summary_table.index.str.contains('1926')]\n",
    "\n",
    "# Trimming Names for desired format\n",
    "for frame in [logs_1965, logs_2000, logs_1926, levels_1965, levels_2000, levels_1926]:\n",
    "    frame.index = [x.split()[0] for x in frame.index]\n",
    "for frame in [logs_1965, logs_2000, logs_1926]:\n",
    "    frame.index = [x.split('_')[1] for x in frame.index]\n",
    "\n",
    "# Multi-Index Header & Combining Quadrants\n",
    "columns = pd.MultiIndex.from_product([['1965-1999', '2000-2024', '1926-2024'], levels_1965.columns])\n",
    "levels = pd.concat([levels_1965, levels_2000, levels_1926], axis=1)\n",
    "levels.columns = columns\n",
    "logs = pd.concat([logs_1965, logs_2000, logs_1926], axis=1)\n",
    "logs.columns = columns\n",
    "\n",
    "pd.concat({'Levels': levels, 'Logs': logs}).style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Factor Pricing Models (LFPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Time Series Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Dependent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Regression (Multiple Dependent Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capm_ts = pmh.calc_iterative_regression(pf_excess_rets.loc['1981':], factors.loc['1981':],\n",
    "                              warnings=False,\n",
    "                              keep_columns=['Alpha', 'Beta', 'R-Squared',\n",
    "                                            'Annualized Treynor Ratio', 'Annualized Information Ratio', \n",
    "                                            'Annualized Tracking Error'])\n",
    "display(capm_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This MAE test is different from the CS MAE test because we measure the MAE of the *alphas* across the TS regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((capm_ts['Annualized Alpha']).abs().mean(), columns = ['MAE (%)'], index = ['CAPM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fama-French 5-Factor Test\n",
    "FF5F = ['MKT', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "ff5f_ts_test = pmh.calc_iterative_regression(portfolios, factors[FF5F], annual_factor=12,intercept=True, \n",
    "                                            keep_columns=['Annualized Alpha', 'R-Squared'])\n",
    "display(ff5f_ts_test)\n",
    "print(f'Mean-Absolute-Error: {ff5f_ts_test['Annualized Alpha'].abs().sum() / len(ff5f_ts_test):.2%}\\\n",
    "      \\nMin-Absolute-Error: {ff5f_ts_test['Annualized Alpha'].abs().idxmin()} - {ff5f_ts_test['Annualized Alpha'].abs().min():.2%}\\\n",
    "      \\nMax-Absolute-Error: {ff5f_ts_test['Annualized Alpha'].abs().idxmax()} - {ff5f_ts_test['Annualized Alpha'].abs().max():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Sectional Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This MAE test is different from the TS MAE test because we measure MAE in the cross-sectional regression as the sum of *error residuals*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capm_cs_test = pmh.calc_cross_section_regression(portfolios, factors['MKT'].to_frame(),provided_excess_returns=True, annual_factor=12, \n",
    "                                                 name='CAPM',keep_columns=['R-Squared', 'Annualized Eta', 'Annualized Lambda', \n",
    "                                                                           'TS Annualized MAE', 'CS Annualized MAE']).T\n",
    "aqr_cs_test = pmh.calc_cross_section_regression(portfolios, factors[AQR],provided_excess_returns=True, annual_factor=12, \n",
    "                                                 name='AQR',keep_columns=['R-Squared', 'Annualized Eta', 'Annualized Lambda', \n",
    "                                                                           'TS Annualized MAE', 'CS Annualized MAE']).T\n",
    "ff3f_cs_test = pmh.calc_cross_section_regression(portfolios, factors[FF3F],provided_excess_returns=True, annual_factor=12, \n",
    "                                                 name='FF3F',keep_columns=['R-Squared', 'Annualized Eta', 'Annualized Lambda', \n",
    "                                                                           'TS Annualized MAE', 'CS Annualized MAE']).T\n",
    "ff5f_cs_test = pmh.calc_cross_section_regression(portfolios, factors[FF5F],provided_excess_returns=True, annual_factor=12, \n",
    "                                                 name='FF5F',keep_columns=['R-Squared', 'Annualized Eta', 'Annualized Lambda', \n",
    "                                                                           'TS Annualized MAE', 'CS Annualized MAE']).T\n",
    "pd.concat([capm_cs_test, aqr_cs_test, ff3f_cs_test, ff5f_cs_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Residuals Covariance Matrix\n",
    "resid = pd.DataFrame()\n",
    "for pf in pf_excess_rets.columns:\n",
    "    r = pmh.calc_regression(pf_excess_rets.loc['1981':, pf], factors.loc['1981':, 'Mkt-RF'].to_frame('Mkt-RF'), \n",
    "                            annual_factor=12, warnings=False, return_model=True, return_fitted_values=False)\n",
    "    r = r.resid.to_frame(pf)\n",
    "    resid = pd.concat([resid, r], axis=1)\n",
    "\n",
    "# Conducting the H- and t-tests (requires residuals from above and alphas from iterative regression)\n",
    "T = pf_excess_rets['1981':].shape[0]\n",
    "SR = (factors['1981':]['Mkt-RF'].mean() / factors['1981':]['Mkt-RF'].std()) #* np.sqrt(12)\n",
    "Sigma = resid.cov()\n",
    "Sigma_inv = pd.DataFrame(np.linalg.inv(Sigma), index=Sigma.index, columns=Sigma.columns)\n",
    "alpha = capm_ts['Alpha']    # Not Annualized\n",
    "\n",
    "H = T * (1 + SR**2)**(-1) * (alpha @ Sigma_inv @ alpha)\n",
    "\n",
    "print('H = {:.2f}'.format(H))\n",
    "pvalue = 1 - chi2.cdf(H, df=25)\n",
    "print('p-value = {:.4f}'.format(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of Under Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_under(mu, sigma, c, h):\n",
    "    return norm.cdf(((c-mu)/sigma) * np.sqrt(h))\n",
    "\n",
    "mu = barn_rets.loc['1965':'1999', 'LOG_SPX-XS'].mean()\n",
    "sigma = barn_rets.loc['1965':'1999', 'LOG_SPX-XS'].std()\n",
    "\n",
    "print(f'From 1965-1999, Monthly:\\n\\tPr(SPX Returns < RF Returns) = {prob_under(mu, sigma, c=0, h=1):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 12*30)\n",
    "y = prob_under(mu, sigma, c=0, h=x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.set_title('Change in Probability of Under-Performance\\nover Different Time Horizons\\n(1965-1999)')\n",
    "ax.set(xlabel='Holding Period\\n(Months)', ylabel='Pr(SPX < RF)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
