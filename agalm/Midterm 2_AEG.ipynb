{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559895d2",
   "metadata": {},
   "source": [
    "# Midterm 2\n",
    "\n",
    "## FINM 36700 - 2024\n",
    "\n",
    "### UChicago Financial Mathematics\n",
    "\n",
    "* Mark Hendricks\n",
    "* hendricks@uchicago.edu\n",
    "\n",
    "### Answers provided by:\n",
    "\n",
    "* Austin Galm\n",
    "* agalm@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cde8d3",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc273c1a",
   "metadata": {},
   "source": [
    "## Please note the following:\n",
    "\n",
    "Points\n",
    "* The exam is 100 points.\n",
    "* You have 120 minutes to complete the exam.\n",
    "* For every minute late you submit the exam, you will lose one point.\n",
    "\n",
    "\n",
    "Submission\n",
    "* You will upload your solution to the `Midterm 2` assignment on Canvas, where you downloaded this. \n",
    "* Be sure to **submit** on Canvas, not just **save** on Canvas.\n",
    "* Your submission should be readable, (the graders can understand your answers.)\n",
    "* Your submission should **include all code used in your analysis in a file format that the code can be executed.** \n",
    "\n",
    "Rules\n",
    "* The exam is open-material, closed-communication.\n",
    "* You do not need to cite material from the course github repo - you are welcome to use the code posted there without citation.\n",
    "\n",
    "Advice\n",
    "* If you find any question to be unclear, state your interpretation and proceed. We will only answer questions of interpretation if there is a typo, error, etc.\n",
    "* The exam will be graded for partial credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f27b1",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "**All data files are found in the class github repo, in the `data` folder.**\n",
    "\n",
    "This exam makes use of the following data files:\n",
    "* `midterm_2_data.xlsx`\n",
    "\n",
    "This file contains the following sheets:\n",
    "- for Section 2:\n",
    "    * `sector stocks excess returns` - MONTHLY excess returns for 49 sector stocks\n",
    "    * `factors excess returns` - MONTHLY excess returns of AQR factor model from Homework 5\n",
    "- for Section 3:\n",
    "    * `factors excess returns` - MONTHLY excess returns of AQR factor model from Homework 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6e066",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "| Problem | Points |\n",
    "|---------|--------|\n",
    "| 1       | 25     |\n",
    "| 2       | 40     |\n",
    "| 3       | 35     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2fc26",
   "metadata": {},
   "source": [
    "### Each numbered question is worth 5 points unless otherwise specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81156e8f",
   "metadata": {},
   "source": [
    "# 1. Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf4bc8",
   "metadata": {},
   "source": [
    "#### No Data Needed\n",
    "\n",
    "These problems do not require any data file. Rather, analyze them conceptually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2ec27",
   "metadata": {},
   "source": [
    "### 1.1.\n",
    "\n",
    "Historically, which pricing factor among the ones we studied has shown a considerable decrease in importance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1760bf7",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "The size factor has exhibited a considerable decrease in importance. This is evidenced in a tangency portfolio test of these factors' excess returns, which was explored in question 2.4 of homework 5.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c8109",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1.2.\n",
    "\n",
    "True or False: For a given factor model and a set of test assets, the addition of one more factor to that model will surely decrease the cross-sectional MAE. \n",
    "\n",
    "True or False: For a given factor model and a set of test assets, the addition of one more factor to that model will surely decrease the time-series MAE. \n",
    "\n",
    "Along with stating T/F, explain your reasoning for the two statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7257ea89",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "1. True, because adding another factor will add another parameter to the regression. Consequently, the model will be able to capture more of the variance in the dataset and have a better $R^2$, which is directly connected to the MAE of the cross-section regression since MAE is calculated in the cross-section regression using the residuals.\n",
    "\n",
    "1. False, the MAE of the TS regression is measured by the alphas (intercepts) from the TS regressions. This alpha can shift up or down with the addition of more regressors to the model. Consequently, it is unclear whether the MAE of the TS regression would decrease with the addition of more factors to the model.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c00026",
   "metadata": {},
   "source": [
    "### 1.3.\n",
    "\n",
    "Consider the scenario in which you are helping two people with investments.\n",
    "\n",
    "* The young person has a 50 year investment horizon.\n",
    "* The elderly person has a 10 year investment horizon.\n",
    "* Both individuals have the same portfolio holdings.\n",
    "\n",
    "State who has the more certain cumulative return and explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54fa49",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "The young person has more certain cumulative returns because they have a longer holding period. This conclusion is supported by the idea of time-diversification, which was explored in the Barnstable case. Time-diversification suggests that investors are rewarded with better risk-adjusted returns when they hold assets for a longer period of time. Intuitively, this is supported by the logic that investors take on more risk of loss over a longer period of time. Mathematically, this is supported by the fact that mean excess returns scale linearly with time while excess return volatility scale sub-linearly through time. Consequently, the sharpe ratio is bound to increase at a rate of $\\sqrt{t}$ where t represents the number of periods the portfolio is held.\n",
    "\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue;\">\n",
    "\n",
    "This question was not a question about time diversification, but rather was a question about variance of returns over time. Consequently, the fact that variance scales linearly with time was the important fact for answering this question, not having a long time-horizon to potentially outperform some benchmark.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d4d72",
   "metadata": {},
   "source": [
    "### 1.4.\n",
    "\n",
    "Suppose we find that the 10-year bond yield works well as a new pricing factor, along with `MKT`.\n",
    "\n",
    "Consider two ways of building this new factor.\n",
    "1. Directly use the index of 10-year yields, `YLD`\n",
    "1. Construct a Fama-French style portfolio of equities, `FFYLD`. (Rank all the stocks by their correlation to bond yield changes, and go long the highest ranked and shor tthe lowest ranked.)\n",
    "\n",
    "Could you test the model with `YLD` and the model with `FFYLD` in the exact same ways? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7667451",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "Yes, you can test these models in the exact same ways even though `YLD` is not a market return series while `FFYLD` is a market return series. The fact that these regressors are different in spirit does not change the approach to specifying the factor model. We will still run a time-series regression of the `YLD` factor and then run a cross-section regression. The testing of these models will come down to the results of the cross-section regression, which will be consistent across models.\n",
    "\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue;\">\n",
    "\n",
    "While the organization of your thoughts was on track, you missed the mark. The time-series regression is still a suitable test and one that you can only conduct on the market-based asset, `FFYLD`. Consequently, the important takeaway here is that the assets are tested differently because only one can be subject to the time-series test.\n",
    "\n",
    "<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf2d238",
   "metadata": {},
   "source": [
    "### 1.5.\n",
    "\n",
    "Suppose we implement a momentum strategy on cryptocurrencies rather than US stocks.\n",
    "\n",
    "Conceptually speaking, but specific to the context of our course discussion, how would the risk profile differ from the momentum strategy of US equities?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e172cb48",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "The risk profile of this momentum strategy would likely be much more volatile for a couple reasons:\n",
    "1. Cryptocurrencies have much more volatile returns by nature.\n",
    "2. There are significantly fewer crypto-currencies in the market than there are stocks\n",
    "\n",
    "The second point is particularly important in the scope of this class because this will lead to a much more concentrated portfolio. In homework 5, we explored how this concentration affects the mean excess returns and volatility of a factor portfolio, finding that these metrics increase in a momentum factor portfolio. In conclusion, the risk of this momentum factor would likely lead to lower risk-adjusted returns compared to a stock-focused momentum factor portfolio.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ce7d4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc093ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, chi2\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "grandparent_dir = os.path.abspath(os.path.join(parent_dir, os.pardir))\n",
    "sys.path.insert(0, parent_dir)\n",
    "sys.path.insert(0, grandparent_dir)\n",
    "import cmds.portfolio_management_helper as pmh\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "PLOT_WIDTH, PLOT_HEIGHT = 8, 5\n",
    "COLORS = [\"blue\", \"red\", \"orange\"]\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "p = plt.rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8a354",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2. Pricing and Tangency Portfolio\n",
    "\n",
    "You work in a hedge fund that believes that the AQR 4-Factor Model (present in Homework 5) is the perfect pricing model for stocks.\n",
    "\n",
    "$$\n",
    "\\mathbb{E} \\left[ \\tilde{r}^i \\right] = \\beta^{i,\\text{MKT}} \\mathbb{E} \\left[ \\tilde{f}_{\\text{MKT}} \\right] + \\beta^{i,\\text{HML}} \\mathbb{E} \\left[ \\tilde{f}_{\\text{HML}} \\right] + \\beta^{i,\\text{RMW}} \\mathbb{E} \\left[ \\tilde{f}_{\\text{RMW}} \\right] + \\beta^{i,\\text{UMD}} \\mathbb{E} \\left[ \\tilde{f}_{\\text{UMD}} \\right]\n",
    "$$\n",
    "\n",
    "The factors are available in the sheet `factors excess returns`.\n",
    "\n",
    "The hedge fund invests in sector-tracking ETFs available in the sheet `sectors excess returns`. You are to allocate into these sectors according to a mean-variance optimization with...\n",
    "\n",
    "* regularization: elements outside the diagonal covariance matrix divided by 2.\n",
    "* modeled risk premia: expected excess returns given by the factor model rather than just using the historic sample averages.\n",
    "\n",
    "You are to train the portfolio and test out-of-sample. The timeframes should be:\n",
    "* Training timeframe: Jan-2018 to Dec-2022.\n",
    "* Testing timeframe: Jan-2023 to most recent observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a5f4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>UMD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>-0.0170</td>\n",
       "      <td>0.0755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-02-01</th>\n",
       "      <td>-0.0122</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01</th>\n",
       "      <td>-0.1290</td>\n",
       "      <td>-0.0101</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>-0.0955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-04-01</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0210</td>\n",
       "      <td>-0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-05-01</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MKT     HML     RMW     UMD\n",
       "date                                      \n",
       "1980-01-01  0.0551  0.0175 -0.0170  0.0755\n",
       "1980-02-01 -0.0122  0.0061  0.0004  0.0788\n",
       "1980-03-01 -0.1290 -0.0101  0.0146 -0.0955\n",
       "1980-04-01  0.0397  0.0106 -0.0210 -0.0043\n",
       "1980-05-01  0.0526  0.0038  0.0034 -0.0112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agric</th>\n",
       "      <th>Food</th>\n",
       "      <th>Soda</th>\n",
       "      <th>Beer</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Toys</th>\n",
       "      <th>Fun</th>\n",
       "      <th>Books</th>\n",
       "      <th>Hshld</th>\n",
       "      <th>Clths</th>\n",
       "      <th>...</th>\n",
       "      <th>Boxes</th>\n",
       "      <th>Trans</th>\n",
       "      <th>Whlsl</th>\n",
       "      <th>Rtail</th>\n",
       "      <th>Meals</th>\n",
       "      <th>Banks</th>\n",
       "      <th>Insur</th>\n",
       "      <th>RlEst</th>\n",
       "      <th>Fin</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>-0.0076</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.0669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-02-01</th>\n",
       "      <td>0.0105</td>\n",
       "      <td>-0.0608</td>\n",
       "      <td>-0.0966</td>\n",
       "      <td>-0.0322</td>\n",
       "      <td>-0.0569</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>-0.0521</td>\n",
       "      <td>-0.0800</td>\n",
       "      <td>-0.0555</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>-0.0541</td>\n",
       "      <td>-0.0346</td>\n",
       "      <td>-0.0639</td>\n",
       "      <td>-0.0652</td>\n",
       "      <td>-0.0854</td>\n",
       "      <td>-0.0959</td>\n",
       "      <td>-0.0347</td>\n",
       "      <td>-0.0282</td>\n",
       "      <td>-0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01</th>\n",
       "      <td>-0.2224</td>\n",
       "      <td>-0.1119</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>-0.1469</td>\n",
       "      <td>-0.0193</td>\n",
       "      <td>-0.1271</td>\n",
       "      <td>-0.0826</td>\n",
       "      <td>-0.1237</td>\n",
       "      <td>-0.0566</td>\n",
       "      <td>-0.0668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0819</td>\n",
       "      <td>-0.1509</td>\n",
       "      <td>-0.1098</td>\n",
       "      <td>-0.0906</td>\n",
       "      <td>-0.1449</td>\n",
       "      <td>-0.0560</td>\n",
       "      <td>-0.0880</td>\n",
       "      <td>-0.2451</td>\n",
       "      <td>-0.1254</td>\n",
       "      <td>-0.1726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-04-01</th>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>-0.0529</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>-0.0103</td>\n",
       "      <td>-0.0312</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-05-01</th>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>0.0877</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.0685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Agric   Food    Soda    Beer    Smoke   Toys    Fun     Books  \\\n",
       "date                                                                         \n",
       "1980-01-01 -0.0076  0.0285  0.0084  0.1009 -0.0143  0.1002  0.0362  0.0323   \n",
       "1980-02-01  0.0105 -0.0608 -0.0966 -0.0322 -0.0569 -0.0323 -0.0521 -0.0800   \n",
       "1980-03-01 -0.2224 -0.1119 -0.0167 -0.1469 -0.0193 -0.1271 -0.0826 -0.1237   \n",
       "1980-04-01  0.0449  0.0766  0.0232  0.0321  0.0830 -0.0529  0.0783  0.0153   \n",
       "1980-05-01  0.0632  0.0793  0.0457  0.0863  0.0815  0.0509  0.0324  0.0886   \n",
       "\n",
       "             Hshld   Clths  ...   Boxes   Trans   Whlsl   Rtail   Meals  \\\n",
       "date                        ...                                           \n",
       "1980-01-01  0.0048  0.0059  ...  0.0158  0.0875  0.0465 -0.0126  0.0430   \n",
       "1980-02-01 -0.0555 -0.0167  ... -0.0079 -0.0541 -0.0346 -0.0639 -0.0652   \n",
       "1980-03-01 -0.0566 -0.0668  ... -0.0819 -0.1509 -0.1098 -0.0906 -0.1449   \n",
       "1980-04-01  0.0304  0.0115  ...  0.0420 -0.0103 -0.0312  0.0353  0.0542   \n",
       "1980-05-01  0.0560  0.0098  ...  0.0564  0.1063  0.1142  0.0877  0.1134   \n",
       "\n",
       "             Banks   Insur   RlEst   Fin     Other  \n",
       "date                                                \n",
       "1980-01-01 -0.0283  0.0258  0.0768  0.0308  0.0669  \n",
       "1980-02-01 -0.0854 -0.0959 -0.0347 -0.0282 -0.0274  \n",
       "1980-03-01 -0.0560 -0.0880 -0.2451 -0.1254 -0.1726  \n",
       "1980-04-01  0.0728  0.0530  0.0977  0.0447  0.0769  \n",
       "1980-05-01  0.0578  0.0557  0.0915  0.0844  0.0685  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = parent_dir + '/data/'\n",
    "ff_file_name = data_path + 'midterm_2_data.xlsx'\n",
    "aqr_xs_rets = pmh.read_excel_default(ff_file_name, \n",
    "                                 sheet_name='factors excess returns',\n",
    "                                 index_col='date', parse_dates=True)\n",
    "sect_xs_rets = pmh.read_excel_default(ff_file_name, \n",
    "                                 sheet_name='sector excess returns',\n",
    "                                 index_col='date', parse_dates=True)\n",
    "\n",
    "display(aqr_xs_rets.head())\n",
    "display(sect_xs_rets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959de7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda represents the premium calculated by the cross-section regression and the historical premium is the average of the factor excess returns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT + HML + RMW + UMD Cross-Section Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MKT Annualized Lambda</th>\n",
       "      <td>0.0999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HML Annualized Lambda</th>\n",
       "      <td>0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMW Annualized Lambda</th>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD Annualized Lambda</th>\n",
       "      <td>0.1236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MKT + HML + RMW + UMD Cross-Section Regression\n",
       "MKT Annualized Lambda                                          0.0999\n",
       "HML Annualized Lambda                                          0.0130\n",
       "RMW Annualized Lambda                                          0.0151\n",
       "UMD Annualized Lambda                                          0.1236"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: I am calculating the cross-section lambdas here as an exercise due to an initial mis-interpretation of the question.\n",
    "\n",
    "aqr_train = aqr_xs_rets.loc['2018':'2022']\n",
    "sect_train = sect_xs_rets.loc['2018':'2022']\n",
    "aqr_test = aqr_xs_rets.loc['2023':]\n",
    "sect_test = sect_xs_rets.loc['2023':]\n",
    "\n",
    "cross_sec_model = pmh.calc_cross_section_regression(sect_train, aqr_train, annual_factor=12, provided_excess_returns=True,\n",
    "                                  keep_columns=['Annualized Eta', 'Annualized Lambda']).T\n",
    "intercept = cross_sec_model.loc['Annualized Eta']\n",
    "lambdas = cross_sec_model.loc[['MKT Annualized Lambda', \n",
    "                               'HML Annualized Lambda', \n",
    "                               'RMW Annualized Lambda', \n",
    "                               'UMD Annualized Lambda']]\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db465bc9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.1.\n",
    "(8pts)\n",
    "\n",
    "Calculate the model-implied expected excess returns of every asset.\n",
    "\n",
    "The time-series estimations should...\n",
    "* NOT include an intercept. (You assume the model holds perfectly.)\n",
    "* use data from the `training` timeframe.\n",
    "\n",
    "With the time-series estimates, use the `training` timeframe's sample average of the factors as the factor premia. Together, this will give you the model-implied risk premia, which we label as\n",
    "$$\n",
    "\\lambda_i := \\mathbb{E}[\\tilde{r}_i]\n",
    "$$\n",
    "\n",
    "* Store $\\lambda_i$ and $\\boldsymbol{\\beta}^i$ for each asset.\n",
    "* Print $\\lambda_i$ for `Agric`, `Food`, `Soda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592ca840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"calc_regression\" assumes excess returns to calculate Information and Treynor Ratios\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d2fdc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d2fdc_level0_col0\" class=\"col_heading level0 col0\" >CS Predicted Excess Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d2fdc_level0_row0\" class=\"row_heading level0 row0\" >Agric</th>\n",
       "      <td id=\"T_d2fdc_row0_col0\" class=\"data row0 col0\" >4.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2fdc_level0_row1\" class=\"row_heading level0 row1\" >Food</th>\n",
       "      <td id=\"T_d2fdc_row1_col0\" class=\"data row1 col0\" >6.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2fdc_level0_row2\" class=\"row_heading level0 row2\" >Soda</th>\n",
       "      <td id=\"T_d2fdc_row2_col0\" class=\"data row2 col0\" >8.80%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f51bec0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas = pmh.calc_iterative_regression(sect_train, aqr_train, annual_factor=12, intercept=False, keep_columns=['Beta'])\n",
    "betas.columns = [c.split(' ')[0] for c in betas.columns]\n",
    "factors_mean_xs = aqr_train.mean() * 12\n",
    "betas.index = [c.split(' ')[0] for c in betas.index]\n",
    "\n",
    "pred_xs_rets = (betas @ factors_mean_xs).to_frame('CS Predicted Excess Returns')\n",
    "pred_xs_rets.iloc[0:3].style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b80c6b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.2.\n",
    "\n",
    "Use the expected excess returns derived from (2.1) with the **regularized** covariance matrix to calculate the weights of the tangency portfolio.\n",
    "\n",
    "- Use the covariance matrix only for `training` timeframe.\n",
    "- Calculate and store the vector of weights for all the assets.\n",
    "- Return the weights of the tangency portfolio for `Agric`, `Food`, `Soda`.\n",
    "\n",
    "$$\n",
    "\\textbf{w}_{t} = \\dfrac{\\tilde{\\Sigma}^{-1} \\bm{\\lambda}}{\\bm{1}' \\tilde{\\Sigma}^{-1} \\bm{\\lambda}}\n",
    "$$\n",
    "\n",
    "Where $\\tilde{\\Sigma}^{-1}$ is the regularized covariance-matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbef32b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4742a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4742a_level0_col0\" class=\"col_heading level0 col0\" >Tangency Regularized 0.50 Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4742a_level0_row0\" class=\"row_heading level0 row0\" >Agric</th>\n",
       "      <td id=\"T_4742a_row0_col0\" class=\"data row0 col0\" >-3.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4742a_level0_row1\" class=\"row_heading level0 row1\" >Food</th>\n",
       "      <td id=\"T_4742a_row1_col0\" class=\"data row1 col0\" >6.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4742a_level0_row2\" class=\"row_heading level0 row2\" >Soda</th>\n",
       "      <td id=\"T_4742a_row2_col0\" class=\"data row2 col0\" >10.44%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f57a3f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the below function, you are estimating the covariance matrix using the predicted excess returns.\n",
    "# However, you need to use the actual excess returns to estimate the covariance matrix.\n",
    "# Then pass the predicted mean excess returns estimated above.\n",
    "pred_rets = aqr_train.apply(lambda x: betas @ x, axis=1)\n",
    "reg_tan_wts = pmh.calc_tangency_weights(pred_rets, cov_mat=0.5)\n",
    "reg_tan_wts.iloc[:3].style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3312ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8ff63\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8ff63_level0_col0\" class=\"col_heading level0 col0\" >CS Predicted Excess Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8ff63_level0_row0\" class=\"row_heading level0 row0\" >Agric</th>\n",
       "      <td id=\"T_8ff63_row0_col0\" class=\"data row0 col0\" >-3.07%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ff63_level0_row1\" class=\"row_heading level0 row1\" >Food </th>\n",
       "      <td id=\"T_8ff63_row1_col0\" class=\"data row1 col0\" >1.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8ff63_level0_row2\" class=\"row_heading level0 row2\" >Soda </th>\n",
       "      <td id=\"T_8ff63_row2_col0\" class=\"data row2 col0\" >13.29%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14e17fe30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corrected Solution:\n",
    "cov = sect_train.cov()\n",
    "SIGMA = (cov + cov * np.eye(cov.shape[0])) / 2\n",
    "lmbda = pred_xs_rets\n",
    "tan_wts = (np.linalg.inv(SIGMA) @ lmbda) / (np.ones(SIGMA.shape[0]).T @ np.linalg.inv(SIGMA) @ lmbda)\n",
    "tan_wts.index = cov.index\n",
    "tan_wts.iloc[:3].style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c171c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.3.\n",
    "\n",
    "Evaluate the performance of this allocation in the `testing` period. Report the **annualized**\n",
    "- mean\n",
    "- vol\n",
    "- Sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8020a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_44fbc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_44fbc_level0_col0\" class=\"col_heading level0 col0\" >Tangency Regularized 0.50 Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_44fbc_level0_row0\" class=\"row_heading level0 row0\" >Annualized Mean</th>\n",
       "      <td id=\"T_44fbc_row0_col0\" class=\"data row0 col0\" >0.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44fbc_level0_row1\" class=\"row_heading level0 row1\" >Annualized Vol</th>\n",
       "      <td id=\"T_44fbc_row1_col0\" class=\"data row1 col0\" >1.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_44fbc_level0_row2\" class=\"row_heading level0 row2\" >Annualized Sharpe</th>\n",
       "      <td id=\"T_44fbc_row2_col0\" class=\"data row2 col0\" >6.12%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f5988c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sect_test.columns = [c.strip() for c in sect_test.columns]\n",
    "pmh.calc_summary_statistics((sect_test.iloc[:, :3] @ reg_tan_wts.iloc[:3]), annual_factor=12, provided_excess_returns=True,\n",
    "                            keep_columns=['Annualized Mean', 'Annualized Vol', 'Annualized Sharpe']).T.style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b1c6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4c43b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4c43b_level0_col0\" class=\"col_heading level0 col0\" >CS Predicted Excess Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4c43b_level0_row0\" class=\"row_heading level0 row0\" >Annualized Mean</th>\n",
       "      <td id=\"T_4c43b_row0_col0\" class=\"data row0 col0\" >18.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c43b_level0_row1\" class=\"row_heading level0 row1\" >Annualized Vol</th>\n",
       "      <td id=\"T_4c43b_row1_col0\" class=\"data row1 col0\" >11.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c43b_level0_row2\" class=\"row_heading level0 row2\" >Annualized Sharpe</th>\n",
       "      <td id=\"T_4c43b_row2_col0\" class=\"data row2 col0\" >151.55%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f57b140>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corrected Solution - Did not need to filter to the specific sectors here...\n",
    "tan_wts.index = [c.strip() for c in tan_wts.index]\n",
    "pmh.calc_summary_statistics((sect_test @ tan_wts), annual_factor=12, provided_excess_returns=True,\n",
    "                            keep_columns=['Annualized Mean', 'Annualized Vol', 'Annualized Sharpe']).iloc[:3].T.style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6f8bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.4.\n",
    "\n",
    "(7pts)\n",
    "\n",
    "Construct the same tangency portfolio as in `2.2` but with one change:\n",
    "* replace the risk premia of the assets, (denoted $\\lambda_i$) with the sample averages of the excess returns from the `training` set.\n",
    "\n",
    "So instead of using $\\lambda_i$ suggested by the factor model (as in `2.1-2.3`) you're using sample averages for $\\lambda_i$.\n",
    "\n",
    "- Return the weights of the tangency portfolio for `Agric`, `Food`, `Soda`.\n",
    "\n",
    "Evaluate the performance of this allocation in the `testing` period. Report the **annualized**\n",
    "- mean\n",
    "- vol\n",
    "- Sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad12dd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a5b52\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a5b52_level0_col0\" class=\"col_heading level0 col0\" >Tangency Regularized 0.50 Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a5b52_level0_row0\" class=\"row_heading level0 row0\" >Agric</th>\n",
       "      <td id=\"T_a5b52_row0_col0\" class=\"data row0 col0\" >14.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a5b52_level0_row1\" class=\"row_heading level0 row1\" >Food </th>\n",
       "      <td id=\"T_a5b52_row1_col0\" class=\"data row1 col0\" >-6.98%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a5b52_level0_row2\" class=\"row_heading level0 row2\" >Soda </th>\n",
       "      <td id=\"T_a5b52_row2_col0\" class=\"data row2 col0\" >32.27%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f7c6c60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reg_tan_wts = pmh.calc_tangency_weights(sect_train, cov_mat=0.5)\n",
    "new_reg_tan_wts.iloc[:3].style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e158ccfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cbf97\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cbf97_level0_col0\" class=\"col_heading level0 col0\" >Tangency Regularized 0.50 Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cbf97_level0_row0\" class=\"row_heading level0 row0\" >Annualized Mean</th>\n",
       "      <td id=\"T_cbf97_row0_col0\" class=\"data row0 col0\" >2.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbf97_level0_row1\" class=\"row_heading level0 row1\" >Annualized Vol</th>\n",
       "      <td id=\"T_cbf97_row1_col0\" class=\"data row1 col0\" >5.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbf97_level0_row2\" class=\"row_heading level0 row2\" >Annualized Sharpe</th>\n",
       "      <td id=\"T_cbf97_row2_col0\" class=\"data row2 col0\" >41.72%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f9afe60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reg_tan_wts.index = [c.strip() for c in new_reg_tan_wts.index]\n",
    "pmh.calc_summary_statistics((sect_test.iloc[:, :3] @ new_reg_tan_wts.iloc[:3]), annual_factor=12, provided_excess_returns=True,\n",
    "                            keep_columns=['Annualized Mean', 'Annualized Vol', 'Annualized Sharpe']).T.style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07dc8aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_695e2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_695e2_level0_col0\" class=\"col_heading level0 col0\" >Tangency Regularized 0.50 Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_695e2_level0_row0\" class=\"row_heading level0 row0\" >Annualized Mean</th>\n",
       "      <td id=\"T_695e2_row0_col0\" class=\"data row0 col0\" >17.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_695e2_level0_row1\" class=\"row_heading level0 row1\" >Annualized Vol</th>\n",
       "      <td id=\"T_695e2_row1_col0\" class=\"data row1 col0\" >15.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_695e2_level0_row2\" class=\"row_heading level0 row2\" >Annualized Sharpe</th>\n",
       "      <td id=\"T_695e2_row2_col0\" class=\"data row2 col0\" >115.55%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f9d92b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corrected - Once again, did not need to filter to the specific sectors here...\n",
    "new_reg_tan_wts.index = [c.strip() for c in new_reg_tan_wts.index]\n",
    "pmh.calc_summary_statistics((sect_test @ new_reg_tan_wts), annual_factor=12, provided_excess_returns=True,\n",
    "                            keep_columns=['Annualized Mean', 'Annualized Vol', 'Annualized Sharpe']).T.style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172cbe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.5.\n",
    "\n",
    "Which allocation performed better in the `testing` period: the allocation based on premia from the factor model or from the sample averages?\n",
    "\n",
    "Why might this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f011c34",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "The allocation built using the historical excess returns performed better in the testing period. This may be because the testing period is using historical returns. Consequently, our tangency portfolio that is constructed using predicted returns won't be as good of a representation of the time series of returns. This could be evidenced by the MAE of the time-series regression, which likely suggests that the predictive power of this model is not as good as we suspect.\n",
    "\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue;\">\n",
    "\n",
    "Corrected: The allocation using the AQR predicted excess returns performed better in the testing period.\n",
    "\n",
    "Generally, we can state that historical returns are bad proxy for expected future returns.\n",
    "\n",
    "On the other hand, generally, historical returns of factors are a better proxy for expected future factor returns. Expected returns (expected premia) of factor models are model stable, leading to better prediction of stock returns, conditional on the stability in the relationship between the factors and the assets ($\\beta_i$). Focusing on factor estimation allows us to estimate the systematic risk component of assets, which is considered the only risk that has a premium.\n",
    "\n",
    "The fact that the expected return model outperformed the historical return model does not imply that the factor model is a perfect pricing model.\n",
    "\n",
    "**Extra**\n",
    "- Numerous studies have demonstrated that portfolios constructed using factor-based expected returns outperform those using historical returns, particularly out-of-sample.\n",
    "- Expected returns from factor models tend to be less extreme compared to historical averages of assets. Thus the expected return of assets also tend to be less extreme when using the factor-based model, thus providing less instability in the Mean-Variance optimization.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a442fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.6.\n",
    "Suppose you now want to build a tangency portfolio solely from the factors, without using the sector ETFs.\n",
    "\n",
    "- Calculate the weights of the tangency portfolio using `training` data for the factors.\n",
    "- Again, regularize the covariance matrix of factor returns by dividing off-diagonal elements by 2.\n",
    "\n",
    "Report, in the `testing` period, the factor-based tangency stats **annualized**...\n",
    "- mean\n",
    "- vol\n",
    "- Sharpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5add306e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a3008\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a3008_level0_col0\" class=\"col_heading level0 col0\" >Tangency Regularized 0.50 Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a3008_level0_row0\" class=\"row_heading level0 row0\" >MKT</th>\n",
       "      <td id=\"T_a3008_row0_col0\" class=\"data row0 col0\" >17.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3008_level0_row1\" class=\"row_heading level0 row1\" >HML</th>\n",
       "      <td id=\"T_a3008_row1_col0\" class=\"data row1 col0\" >-1.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3008_level0_row2\" class=\"row_heading level0 row2\" >RMW</th>\n",
       "      <td id=\"T_a3008_row2_col0\" class=\"data row2 col0\" >59.84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a3008_level0_row3\" class=\"row_heading level0 row3\" >UMD</th>\n",
       "      <td id=\"T_a3008_row3_col0\" class=\"data row3 col0\" >24.09%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f74be30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_reg_tan_wts = pmh.calc_tangency_weights(aqr_train, cov_mat=0.5)\n",
    "factor_reg_tan_wts.style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01fd10d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_508da\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_508da_level0_col0\" class=\"col_heading level0 col0\" >Tangency Regularized 0.50 Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_508da_level0_row0\" class=\"row_heading level0 row0\" >Annualized Mean</th>\n",
       "      <td id=\"T_508da_row0_col0\" class=\"data row0 col0\" >6.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_508da_level0_row1\" class=\"row_heading level0 row1\" >Annualized Vol</th>\n",
       "      <td id=\"T_508da_row1_col0\" class=\"data row1 col0\" >5.82%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_508da_level0_row2\" class=\"row_heading level0 row2\" >Annualized Sharpe</th>\n",
       "      <td id=\"T_508da_row2_col0\" class=\"data row2 col0\" >107.19%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f591220>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmh.calc_summary_statistics((aqr_test @ factor_reg_tan_wts), annual_factor=12, provided_excess_returns=True,\n",
    "                            keep_columns=['Annualized Mean', 'Annualized Vol', 'Annualized Sharpe']).T.style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6cc36",
   "metadata": {},
   "source": [
    "### 2.7.\n",
    "\n",
    "Based on the hedge fund's beliefs, would you prefer to use the ETF-based tangency or the factor-based tangency portfolio? Explain your reasoning. Note that you should answer based on broad principles and not on the particular estimation results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfef9f5e",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "I would prefer to use the factor-based tangency portfolio because it provides better risk-adjusted (and absolute mean-excess) returns. However, I state this assuming that the factor portfolios are constructed in a way that they use the securities that underly the ETFs. Consequently, the investment universe using either approach results in investing in the same fundamental securities (i.e: set of company stocks). Therefore, using the factor portfolios seems to provide access to a better weighting scheme than the MVO portfolio constructed using the ETFs.\n",
    "\n",
    "However, if the factor portfolios do not represent the same universe of assets, then I would prefer to use the ETF-based tangency portfolio because it is a better representation of the value I am endeavoring to provide to my investors. \n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8eda25",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff849e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 3. Long-Run Returns\n",
    "\n",
    "For this question, use only the sheet `factors excess returns`.\n",
    "\n",
    "Suppose we want to measure the long run returns of various pricing factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be343b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.1.\n",
    "\n",
    "Turn the data into log returns.\n",
    "- Display the first 5 rows of the data.\n",
    "\n",
    "Using these log returns, report the **annualized**\n",
    "* mean\n",
    "* vol\n",
    "* Sharpe\n",
    "\n",
    "### 3.2.\n",
    "\n",
    "Consider 15-year cumulative log excess returns. Following the assumptions and modeling of Lecture 6, report the following 15-year stats:\n",
    "- mean\n",
    "- vol\n",
    "- Sharpe\n",
    "\n",
    "How do they compare to the estimated stats (1-year horizon) in `3.1`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bf3468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>UMD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>-0.0171</td>\n",
       "      <td>0.0728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-02-01</th>\n",
       "      <td>-0.0123</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-03-01</th>\n",
       "      <td>-0.1381</td>\n",
       "      <td>-0.0102</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>-0.1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-04-01</th>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>-0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-05-01</th>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MKT     HML     RMW     UMD\n",
       "date                                      \n",
       "1980-01-01  0.0536  0.0173 -0.0171  0.0728\n",
       "1980-02-01 -0.0123  0.0061  0.0004  0.0758\n",
       "1980-03-01 -0.1381 -0.0102  0.0145 -0.1004\n",
       "1980-04-01  0.0389  0.0105 -0.0212 -0.0043\n",
       "1980-05-01  0.0513  0.0038  0.0034 -0.0113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_008d8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_008d8_level0_col0\" class=\"col_heading level0 col0\" >MKT</th>\n",
       "      <th id=\"T_008d8_level0_col1\" class=\"col_heading level0 col1\" >HML</th>\n",
       "      <th id=\"T_008d8_level0_col2\" class=\"col_heading level0 col2\" >RMW</th>\n",
       "      <th id=\"T_008d8_level0_col3\" class=\"col_heading level0 col3\" >UMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_008d8_level0_row0\" class=\"row_heading level0 row0\" >Annualized Mean</th>\n",
       "      <td id=\"T_008d8_row0_col0\" class=\"data row0 col0\" >7.35%</td>\n",
       "      <td id=\"T_008d8_row0_col1\" class=\"data row0 col1\" >1.98%</td>\n",
       "      <td id=\"T_008d8_row0_col2\" class=\"data row0 col2\" >4.35%</td>\n",
       "      <td id=\"T_008d8_row0_col3\" class=\"data row0 col3\" >5.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_008d8_level0_row1\" class=\"row_heading level0 row1\" >Annualized Vol</th>\n",
       "      <td id=\"T_008d8_row1_col0\" class=\"data row1 col0\" >15.88%</td>\n",
       "      <td id=\"T_008d8_row1_col1\" class=\"data row1 col1\" >10.98%</td>\n",
       "      <td id=\"T_008d8_row1_col2\" class=\"data row1 col2\" >8.36%</td>\n",
       "      <td id=\"T_008d8_row1_col3\" class=\"data row1 col3\" >16.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_008d8_level0_row2\" class=\"row_heading level0 row2\" >Annualized Sharpe</th>\n",
       "      <td id=\"T_008d8_row2_col0\" class=\"data row2 col0\" >46.30%</td>\n",
       "      <td id=\"T_008d8_row2_col1\" class=\"data row2 col1\" >18.01%</td>\n",
       "      <td id=\"T_008d8_row2_col2\" class=\"data row2 col2\" >52.10%</td>\n",
       "      <td id=\"T_008d8_row2_col3\" class=\"data row2 col3\" >31.22%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f9d8dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answering 3.1 - Corrected\n",
    "aqr_log_rets = np.log(1+aqr_xs_rets)\n",
    "display(aqr_log_rets.head())\n",
    "display(pmh.calc_summary_statistics(aqr_log_rets, annual_factor=12, provided_excess_returns=True,\n",
    "                            keep_columns=['Annualized Mean', 'Annualized Vol', 'Annualized Sharpe']).T.style.format('{:.2%}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1110bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_438ae\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_438ae_level0_col0\" class=\"col_heading level0 col0\" >MKT</th>\n",
       "      <th id=\"T_438ae_level0_col1\" class=\"col_heading level0 col1\" >HML</th>\n",
       "      <th id=\"T_438ae_level0_col2\" class=\"col_heading level0 col2\" >RMW</th>\n",
       "      <th id=\"T_438ae_level0_col3\" class=\"col_heading level0 col3\" >UMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_438ae_level0_row0\" class=\"row_heading level0 row0\" >Annualized Mean</th>\n",
       "      <td id=\"T_438ae_row0_col0\" class=\"data row0 col0\" >110.32%</td>\n",
       "      <td id=\"T_438ae_row0_col1\" class=\"data row0 col1\" >29.65%</td>\n",
       "      <td id=\"T_438ae_row0_col2\" class=\"data row0 col2\" >65.31%</td>\n",
       "      <td id=\"T_438ae_row0_col3\" class=\"data row0 col3\" >75.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_438ae_level0_row1\" class=\"row_heading level0 row1\" >Annualized Vol</th>\n",
       "      <td id=\"T_438ae_row1_col0\" class=\"data row1 col0\" >61.52%</td>\n",
       "      <td id=\"T_438ae_row1_col1\" class=\"data row1 col1\" >42.52%</td>\n",
       "      <td id=\"T_438ae_row1_col2\" class=\"data row1 col2\" >32.37%</td>\n",
       "      <td id=\"T_438ae_row1_col3\" class=\"data row1 col3\" >62.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_438ae_level0_row2\" class=\"row_heading level0 row2\" >Annualized Sharpe</th>\n",
       "      <td id=\"T_438ae_row2_col0\" class=\"data row2 col0\" >179.33%</td>\n",
       "      <td id=\"T_438ae_row2_col1\" class=\"data row2 col1\" >69.75%</td>\n",
       "      <td id=\"T_438ae_row2_col2\" class=\"data row2 col2\" >201.77%</td>\n",
       "      <td id=\"T_438ae_row2_col3\" class=\"data row2 col3\" >120.93%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f9dbd40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answering 3.2 - Corrected\n",
    "# long_run_rets = aqr_log_rets.rolling(window=12*15).sum()\n",
    "pmh.calc_summary_statistics(aqr_log_rets, annual_factor=12*15, provided_excess_returns=True,\n",
    "                            keep_columns=['Annualized Mean', 'Annualized Vol', 'Annualized Sharpe']).T.style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c43535e",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "The stats for the 15-year returns is substantially better than the 1-year returns horizon. This is a classic example of the benefits of time-diversification that was offered in the Barnstable case. This result shows that the excess mean returns scale linearly while the volatility of the excess returns only scales sub-linearly. Consequently, the risk-adjusted returns are substantially better.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181ba0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.3.\n",
    "\n",
    "What is the probability that momentum factor has a negative mean excess return over the next \n",
    "* single period?\n",
    "* 15 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c1e8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Period:\n",
      "\tPr(Mean Excess Rets < 0) = 46.41%\n",
      "15-Year:\n",
      "\tPr(Mean Excess Rets < 0) = 11.33%\n"
     ]
    }
   ],
   "source": [
    "def prob_under(mu, sigma, c, h):\n",
    "    return norm.cdf(((c-mu)/sigma) * np.sqrt(h))\n",
    "\n",
    "mu = aqr_log_rets.loc[:, 'UMD'].mean()\n",
    "sigma = aqr_log_rets.loc[:, 'UMD'].std()\n",
    "\n",
    "print(f'Single Period:\\n\\tPr(Mean Excess Rets < 0) = {prob_under(mu, sigma, c=0, h=1):.2%}')\n",
    "print(f'15-Year:\\n\\tPr(Mean Excess Rets < 0) = {prob_under(mu, sigma, c=0, h=12*15):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a137b86c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.4.\n",
    "\n",
    "Recall from the case that momentum has been underperforming since 2009. \n",
    "\n",
    "Using data from 2009 to present, what is the probability that momentum *outperforms* the market factor over the next\n",
    "* period?\n",
    "* 15 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a092a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Period:\n",
      "\tPr(UMD Mean Excess Rets > MKT) = 43.20%\n",
      "15-Year:\n",
      "\tPr(UMD Mean Excess Rets > MKT) = 1.07%\n"
     ]
    }
   ],
   "source": [
    "# Corrected\n",
    "mu = aqr_log_rets.loc['2009':, 'UMD'].mean()\n",
    "sigma = aqr_log_rets.loc['2009':, 'UMD'].std()\n",
    "c = aqr_log_rets.loc[:, 'MKT'].mean()\n",
    "\n",
    "print(f'Single Period:\\n\\tPr(UMD Mean Excess Rets > MKT) = {1-prob_under(mu, sigma, c=c, h=1):.2%}')\n",
    "print(f'15-Year:\\n\\tPr(UMD Mean Excess Rets > MKT) = {1-prob_under(mu, sigma, c=c, h=12*15):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678bc07",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.5.\n",
    "Conceptually, why is there such a discrepancy between this probability for 1 period vs. 15 years?\n",
    "\n",
    "What assumption about the log-returns are we making when we use this technique to estimate underperformance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850277e",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "The probability of outperformance over the first period is less than 50%. This suggests that momentum underperforms the market factor on average. When we then analyze cumulative returns over a longer time horizon, those returns cumulate. So, if the momentum factors is expected to underperform the market factor on average in a single period, then the probability that it outperforms must diminish as we look at longer-term returns. This is because we would expect the momentum to cumulate at a slower pace than the market factor.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f33b7",
   "metadata": {},
   "source": [
    "### 3.6.\n",
    "\n",
    "Using your previous answers, explain what is meant by time diversification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40f0d0",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "Time diversification refers to the idea that returns become \"safer\" as the holding period lengthens. This conclusion is drawn from the mathematical fact that returns scale linearly with time while volatility of returns scales sub-linearly with time. Consequently, the risk-adjusted returns of a longer holding period investment is expected to be higher than a shorter holding-period investment.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5080207",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.7.\n",
    "\n",
    "Is the probability that `HML` and `UMD` both have negative cumulative returns over the next year higher or lower than the probability that `HML` and `MKT` both have negative cumulative returns over the next year?\n",
    "\n",
    "Answer conceptually, but specifically. (No need to calculate the specific probabilities.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e02e4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HML Single Period:\n",
      "\tPr(Mean Excess Rets < 0) = 42.85%\n",
      "UMD Single Period:\n",
      "\tPr(Mean Excess Rets < 0) = 37.74%\n",
      "MKT Single Period:\n",
      "\tPr(Mean Excess Rets < 0) = 32.17%\n"
     ]
    }
   ],
   "source": [
    "mu = aqr_log_rets.loc[:, 'HML'].mean()\n",
    "sigma = aqr_log_rets.loc[:, 'HML'].std()\n",
    "print(f'HML Single Period:\\n\\tPr(Mean Excess Rets < 0) = {prob_under(mu, sigma, c=0, h=12):.2%}')\n",
    "\n",
    "mu = aqr_log_rets.loc[:, 'UMD'].mean()\n",
    "sigma = aqr_log_rets.loc[:, 'UMD'].std()\n",
    "print(f'UMD Single Period:\\n\\tPr(Mean Excess Rets < 0) = {prob_under(mu, sigma, c=0, h=12):.2%}')\n",
    "\n",
    "mu = aqr_log_rets.loc[:, 'MKT'].mean()\n",
    "sigma = aqr_log_rets.loc[:, 'MKT'].std()\n",
    "print(f'MKT Single Period:\\n\\tPr(Mean Excess Rets < 0) = {prob_under(mu, sigma, c=0, h=12):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2014cd6",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">\n",
    "\n",
    "The HML factor has the highest probability of experiencing negative returns over the next year, followed by UMD and then the Market. Consequently, we can conclude that the probability that both the HML and UMD factors both have negative cumulative excess returns over the next year is higher than the probability that both the HML and MKT factors have negative cumulative excess returns over the next year. \n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf51ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
